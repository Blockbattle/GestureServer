{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKUIwvMTZBoL",
        "outputId": "abe6e41a-f4bb-48cf-d147-86a1782883c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H5kArVqYzlw",
        "outputId": "6d71edbd-1e99-4b28-80bc-4699ad3a1343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLe3nxMKvXbe"
      },
      "source": [
        "Подключаем необходимые библиотеки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlDTVdnRYMDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a7acc5-6abb-4fde-9199-530224d73b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from matplotlib import pyplot\n",
        "import seaborn as sns\n",
        "from kerastuner.tuners import BayesianOptimization\n",
        "from kerastuner import HyperParameters\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LytFcppUYMDJ"
      },
      "source": [
        "Загружаем тренировочные и тестовые данные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqQ7Lg8fYMDK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f78d48c4-1195-4ad3-bd2a-2f8fd279ba1b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'space']\n",
        "\n",
        "def barplot(y, s):\n",
        "  vc = np.sum(y, 0)\n",
        "  pyplot.figure(figsize=(20, 5))\n",
        "  sns.barplot(x=labels, y=vc, palette=\"rocket\")\n",
        "  pyplot.title(s, fontsize=15)\n",
        "  pyplot.show()\n",
        "\n",
        "files = ['landmarks_x.txt', 'landmarks_y.txt']\n",
        "x = list()\n",
        "for file in files:\n",
        "    data = read_csv('drive/MyDrive/Gestures/' + file, header=None, delim_whitespace=True).values\n",
        "    x.append(data)\n",
        "\n",
        "x = np.dstack(x)\n",
        "\n",
        "y = to_categorical(read_csv('drive/MyDrive/Gestures/labels.txt', header=None, delim_whitespace=True).values)\n",
        "barplot(y, \"Number of landmarks of each category\")\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
        "                                                    train_size=0.7, \n",
        "                                                    random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, \n",
        "                                                    train_size=0.8, \n",
        "                                                    random_state=42)\n",
        "barplot(y_train, \"Train\")\n",
        "barplot(y_test, \"Test\")\n",
        "barplot(y_val, \"Validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S20_ZZuuYMDK"
      },
      "source": [
        "Сначала попробуем предсказать данные на простой RNN. Подготавливаем функцию создания модели и, используя тюнер, подбираем параметры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKgDfX6mwUHW"
      },
      "outputs": [],
      "source": [
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
        "\n",
        "def build_modelRNN(hp):\n",
        "    model = Sequential()\n",
        "    activation_choice = hp.Choice('activation', values=['relu', 'elu', 'selu'])\n",
        "\n",
        "    k = hp.Int('num_srnn', 0, 2)\n",
        "    if k == 0:\n",
        "      model.add(SimpleRNN(hp.Int('srnn1', min_value=32, max_value=300,step=32), input_shape=(n_timesteps,n_features)))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "    elif k == 1:\n",
        "      model.add(SimpleRNN(hp.Int('srnn1', min_value=32, max_value=300,step=32), input_shape=(n_timesteps,n_features), return_sequences=True))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "      model.add(SimpleRNN(hp.Int('srnn2', min_value=32, max_value=300,step=32)))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "    elif k == 2:\n",
        "      model.add(SimpleRNN(hp.Int('srnn1', min_value=32, max_value=300,step=32), input_shape=(n_timesteps,n_features), return_sequences=True))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "      model.add(SimpleRNN(hp.Int('srnn2', min_value=32, max_value=300,step=32), return_sequences=True))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "      model.add(SimpleRNN(hp.Int('srnn3', min_value=32, max_value=300,step=32)))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "\n",
        "    for j in range(hp.Int('num_denses', 0, 2)):\n",
        "        model.add(Dense(units=hp.Int('dense_' + str(j), min_value=128, max_value=800,step=32), activation=activation_choice))\n",
        "        model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "        \n",
        "    model.add(Dense(n_outputs, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=hp.Choice('optimizer', values=['adam','rmsprop','SGD']),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYGZ8pfJwUZ8",
        "outputId": "937fa21b-8a74-47f7-e7f0-cd8053bc8ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 6\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu', 'selu'], 'ordered': False}\n",
            "num_srnn (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 2, 'step': 1, 'sampling': None}\n",
            "srnn1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 300, 'step': 32, 'sampling': None}\n",
            "dropout_coef (Float)\n",
            "{'default': 0.05, 'conditions': [], 'min_value': 0.05, 'max_value': 0.9, 'step': 0.1, 'sampling': None}\n",
            "num_denses (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 2, 'step': 1, 'sampling': None}\n",
            "optimizer (Choice)\n",
            "{'default': 'adam', 'conditions': [], 'values': ['adam', 'rmsprop', 'SGD'], 'ordered': False}\n"
          ]
        }
      ],
      "source": [
        "hp3 = HyperParameters()\n",
        "\n",
        "tuner3 = BayesianOptimization(\n",
        "    build_modelRNN,\n",
        "    hyperparameters=hp3,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=12,              \n",
        "    directory='gesture'\n",
        "    )\n",
        "tuner3.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner3.search(x_train,\n",
        "             y_train,\n",
        "             validation_data=(x_val, y_val),\n",
        "             batch_size=hp3.Int('batch_size', min_value=64, max_value=1024, step=32),\n",
        "             epochs=8,\n",
        "             callbacks=[EarlyStopping(monitor='val_loss', patience=3,\n",
        "                            restore_best_weights=True)]\n",
        "             )\n",
        "\n",
        "tuner3.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c5psNU-xPLI",
        "outputId": "ddcc3b31-f985-4b66-a054-5553c9f1532e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 12 Complete [00h 05m 40s]\n",
            "val_accuracy: 0.9910112619400024\n",
            "\n",
            "Best val_accuracy So Far: 0.9981273412704468\n",
            "Total elapsed time: 01h 03m 20s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Results summary\n",
            "Results in gesture/untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_srnn: 1\n",
            "srnn1: 64\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "srnn2: 224\n",
            "srnn3: 32\n",
            "dense_0: 480\n",
            "dense_1: 128\n",
            "Score: 0.9981273412704468\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_srnn: 2\n",
            "srnn1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 1\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "srnn2: 32\n",
            "srnn3: 32\n",
            "dense_0: 128\n",
            "Score: 0.9980024695396423\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_srnn: 2\n",
            "srnn1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: SGD\n",
            "batch_size: 352\n",
            "srnn2: 256\n",
            "srnn3: 192\n",
            "dense_0: 128\n",
            "dense_1: 128\n",
            "Score: 0.9975031018257141\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_srnn: 2\n",
            "srnn1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 64\n",
            "srnn2: 32\n",
            "srnn3: 32\n",
            "dense_0: 128\n",
            "dense_1: 800\n",
            "Score: 0.9973782896995544\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_srnn: 0\n",
            "srnn1: 96\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 256\n",
            "srnn2: 32\n",
            "srnn3: 128\n",
            "dense_0: 352\n",
            "dense_1: 128\n",
            "Score: 0.99725341796875\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_srnn: 2\n",
            "srnn1: 288\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 256\n",
            "srnn2: 32\n",
            "srnn3: 32\n",
            "dense_0: 800\n",
            "dense_1: 128\n",
            "Score: 0.9937577843666077\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_srnn: 1\n",
            "srnn1: 288\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: rmsprop\n",
            "batch_size: 1024\n",
            "srnn2: 32\n",
            "srnn3: 128\n",
            "dense_0: 128\n",
            "dense_1: 480\n",
            "Score: 0.9935081005096436\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_srnn: 1\n",
            "srnn1: 96\n",
            "dropout_coef: 0.7500000000000002\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 800\n",
            "srnn2: 32\n",
            "Score: 0.9912609457969666\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_srnn: 2\n",
            "srnn1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 1\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "srnn2: 32\n",
            "srnn3: 288\n",
            "dense_0: 640\n",
            "Score: 0.9912609457969666\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_srnn: 1\n",
            "srnn1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: SGD\n",
            "batch_size: 1024\n",
            "srnn2: 32\n",
            "srnn3: 32\n",
            "dense_0: 800\n",
            "dense_1: 800\n",
            "Score: 0.9910112619400024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучаем и сохраняем лучшую модель"
      ],
      "metadata": {
        "id": "VgxB0hnvun4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs, batch_size = 50, 1024\n",
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
        "model6 = Sequential()\n",
        "model6.add(SimpleRNN(64, input_shape=(n_timesteps,n_features), return_sequences=True))\n",
        "model6.add(Dropout(0.05))\n",
        "model6.add(SimpleRNN(224))\n",
        "model6.add(Dropout(0.05))\n",
        "model6.add(Dense(n_outputs, activation='softmax'))\n",
        "model6.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "loss6 = model6.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)], shuffle = True)\n",
        "_, accuracy = model6.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "model6.summary()\n",
        "print('Accuracy: %.5f' % accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5UfeVuViffb",
        "outputId": "b7debb07-bc2a-4b32-f5b4-a8c6e82bbb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 5s 98ms/step - loss: 1.3775 - accuracy: 0.6889 - val_loss: 0.3469 - val_accuracy: 0.9596\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 3s 84ms/step - loss: 0.2173 - accuracy: 0.9602 - val_loss: 0.1101 - val_accuracy: 0.9853\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 3s 83ms/step - loss: 0.0858 - accuracy: 0.9865 - val_loss: 0.0617 - val_accuracy: 0.9914\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 3s 85ms/step - loss: 0.0513 - accuracy: 0.9927 - val_loss: 0.0378 - val_accuracy: 0.9955\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0355 - accuracy: 0.9948 - val_loss: 0.0321 - val_accuracy: 0.9959\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.1345 - accuracy: 0.9692 - val_loss: 0.0492 - val_accuracy: 0.9925\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0351 - accuracy: 0.9948 - val_loss: 0.0238 - val_accuracy: 0.9966\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0261 - accuracy: 0.9952 - val_loss: 0.0284 - val_accuracy: 0.9929\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0766 - accuracy: 0.9749 - val_loss: 0.0273 - val_accuracy: 0.9964\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0189 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9980\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 3s 85ms/step - loss: 0.0144 - accuracy: 0.9975 - val_loss: 0.0122 - val_accuracy: 0.9980\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 3s 85ms/step - loss: 0.0112 - accuracy: 0.9984 - val_loss: 0.0107 - val_accuracy: 0.9980\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 3s 82ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0095 - val_accuracy: 0.9983\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 3s 83ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0086 - val_accuracy: 0.9990\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.0086 - val_accuracy: 0.9990\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.0074 - val_accuracy: 0.9993\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.0076 - val_accuracy: 0.9990\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0069 - val_accuracy: 0.9994\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.0071 - val_accuracy: 0.9991\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0080 - val_accuracy: 0.9989\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9991\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0077 - val_accuracy: 0.9986\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 3s 84ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0067 - val_accuracy: 0.9991\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 3s 85ms/step - loss: 0.0398 - accuracy: 0.9862 - val_loss: 0.0308 - val_accuracy: 0.9904\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.0074 - val_accuracy: 0.9989\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 3s 84ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0053 - val_accuracy: 0.9994\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 3s 83ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0054 - val_accuracy: 0.9990\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 3s 85ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0051 - val_accuracy: 0.9993\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0059 - val_accuracy: 0.9990\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0051 - val_accuracy: 0.9991\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 3s 84ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0054 - val_accuracy: 0.9989\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0058 - val_accuracy: 0.9989\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0051 - val_accuracy: 0.9989\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 3s 85ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9990\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 3s 84ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9989\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 3s 84ms/step - loss: 0.2098 - accuracy: 0.9431 - val_loss: 0.0256 - val_accuracy: 0.9963\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 3s 83ms/step - loss: 0.0175 - accuracy: 0.9967 - val_loss: 0.0096 - val_accuracy: 0.9985\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.0075 - val_accuracy: 0.9988\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.0062 - val_accuracy: 0.9991\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 3s 85ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0064 - val_accuracy: 0.9988\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 3s 84ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 0.9991\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 0.9994\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_52 (SimpleRNN)   (None, 21, 64)            4288      \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 21, 64)            0         \n",
            "                                                                 \n",
            " simple_rnn_53 (SimpleRNN)   (None, 224)               64736     \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 224)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 27)                6075      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75,099\n",
            "Trainable params: 75,099\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 0.99942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.save('drive/My Drive/gr_rnn01_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRtQJBv7tuFQ",
        "outputId": "6598bba0-74be-4c4d-d02b-3f756c24c598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_rnn01_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучаем и сохраняем пять лучших моделей"
      ],
      "metadata": {
        "id": "dORt4ZAYu5WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models1 = tuner3.get_best_models(num_models=5)\n",
        "i = 0\n",
        "for model in models1:\n",
        "  i = i + 1\n",
        "  if (i == 1 or i == 2):\n",
        "    batch_size = 1024\n",
        "  elif i == 3:\n",
        "    batch_size = 352\n",
        "  elif i == 4:\n",
        "    batch_size = 64\n",
        "  else:\n",
        "    batch_size = 256\n",
        "  model.summary()\n",
        "  model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=batch_size, callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)], shuffle = True)\n",
        "  _, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "  print()\n",
        "  model.save('drive/My Drive/gr_rnn' + str(i) + '_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUBBnLt2C92S",
        "outputId": "1e690119-3a19-4d4e-9754-1f3d750b48a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 21, 64)            4288      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 21, 64)            0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 224)               64736     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 224)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 27)                6075      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75,099\n",
            "Trainable params: 75,099\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "32/32 [==============================] - 5s 91ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.0055 - val_accuracy: 0.9991\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 3s 80ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 3s 81ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 3s 81ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 3s 79ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 3s 79ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 3s 82ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 3s 81ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 3s 82ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 3s 80ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 0.9995\n",
            "\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_rnn1_model/assets\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 21, 32)            1120      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 21, 32)            0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 21, 32)            2080      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 21, 32)            0         \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               4224      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 27)                3483      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,987\n",
            "Trainable params: 12,987\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 7s 131ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 4s 119ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 4s 121ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 4s 116ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 4s 117ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 4s 119ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 4s 114ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 0.9993\n",
            "\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_rnn2_model/assets\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 21, 32)            1120      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 21, 32)            0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 21, 256)           73984     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 21, 256)           0         \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 192)               86208     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 192)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 27)                5211      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 166,523\n",
            "Trainable params: 166,523\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "92/92 [==============================] - 14s 122ms/step - loss: 0.0271 - accuracy: 0.9970 - val_loss: 0.0234 - val_accuracy: 0.9970\n",
            "Epoch 2/10\n",
            "92/92 [==============================] - 10s 111ms/step - loss: 0.0260 - accuracy: 0.9972 - val_loss: 0.0220 - val_accuracy: 0.9974\n",
            "Epoch 3/10\n",
            "92/92 [==============================] - 10s 113ms/step - loss: 0.0246 - accuracy: 0.9974 - val_loss: 0.0224 - val_accuracy: 0.9975\n",
            "Epoch 4/10\n",
            "92/92 [==============================] - 10s 112ms/step - loss: 0.0244 - accuracy: 0.9972 - val_loss: 0.0211 - val_accuracy: 0.9975\n",
            "Epoch 5/10\n",
            "92/92 [==============================] - 10s 113ms/step - loss: 0.0237 - accuracy: 0.9972 - val_loss: 0.0199 - val_accuracy: 0.9974\n",
            "Epoch 6/10\n",
            "92/92 [==============================] - 10s 112ms/step - loss: 0.0227 - accuracy: 0.9977 - val_loss: 0.0197 - val_accuracy: 0.9974\n",
            "Epoch 7/10\n",
            "92/92 [==============================] - 10s 109ms/step - loss: 0.0220 - accuracy: 0.9976 - val_loss: 0.0187 - val_accuracy: 0.9978\n",
            "Epoch 8/10\n",
            "92/92 [==============================] - 10s 109ms/step - loss: 0.0220 - accuracy: 0.9971 - val_loss: 0.0184 - val_accuracy: 0.9975\n",
            "Epoch 9/10\n",
            "92/92 [==============================] - 10s 109ms/step - loss: 0.0209 - accuracy: 0.9975 - val_loss: 0.0180 - val_accuracy: 0.9978\n",
            "Epoch 10/10\n",
            "92/92 [==============================] - 10s 110ms/step - loss: 0.0207 - accuracy: 0.9973 - val_loss: 0.0170 - val_accuracy: 0.9979\n",
            "49/49 [==============================] - 1s 14ms/step - loss: 0.0152 - accuracy: 0.9981\n",
            "\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_rnn3_model/assets\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 21, 32)            1120      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 21, 32)            0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 21, 32)            2080      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 21, 32)            0         \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 27)                891       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,171\n",
            "Trainable params: 6,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "501/501 [==============================] - 55s 104ms/step - loss: 0.0278 - accuracy: 0.9931 - val_loss: 0.0169 - val_accuracy: 0.9953\n",
            "Epoch 2/10\n",
            "501/501 [==============================] - 51s 102ms/step - loss: 0.0203 - accuracy: 0.9951 - val_loss: 0.0083 - val_accuracy: 0.9983\n",
            "Epoch 3/10\n",
            "501/501 [==============================] - 53s 105ms/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.0152 - val_accuracy: 0.9966\n",
            "Epoch 4/10\n",
            "501/501 [==============================] - 53s 105ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.0235 - val_accuracy: 0.9929\n",
            "Epoch 5/10\n",
            "501/501 [==============================] - 53s 105ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0270 - val_accuracy: 0.9915\n",
            "269/269 [==============================] - 3s 12ms/step - loss: 0.0063 - accuracy: 0.9988\n",
            "\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_rnn4_model/assets\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 96)                9504      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 96)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 27)                2619      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,123\n",
            "Trainable params: 12,123\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "126/126 [==============================] - 5s 36ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.0073 - val_accuracy: 0.9991\n",
            "Epoch 2/10\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.0063 - val_accuracy: 0.9994\n",
            "Epoch 3/10\n",
            "126/126 [==============================] - 4s 32ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.0063 - val_accuracy: 0.9993\n",
            "Epoch 4/10\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.0061 - val_accuracy: 0.9991\n",
            "Epoch 5/10\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9990\n",
            "Epoch 6/10\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9989\n",
            "Epoch 7/10\n",
            "126/126 [==============================] - 4s 35ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0056 - val_accuracy: 0.9991\n",
            "Epoch 8/10\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
            "Epoch 9/10\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9989\n",
            "Epoch 10/10\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.9991\n",
            "\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_rnn5_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ещё один поиск"
      ],
      "metadata": {
        "id": "U0azxkRMu-wR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMJVBtKOwUh5",
        "outputId": "0aa7872c-7f60-4006-8c0f-b4d6ee526776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 12 Complete [00h 05m 24s]\n",
            "val_accuracy: 0.9940074682235718\n",
            "\n",
            "Best val_accuracy So Far: 0.9970037341117859\n",
            "Total elapsed time: 00h 53m 53s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Results summary\n",
            "Results in gesture/untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_gru: 0\n",
            "srnn1: 288\n",
            "dropout_coef: 0.35000000000000003\n",
            "num_denses: 1\n",
            "optimizer: adam\n",
            "batch_size: 736\n",
            "srnn2: 288\n",
            "dense_0: 128\n",
            "srnn3: 32\n",
            "Score: 0.9970037341117859\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: elu\n",
            "num_gru: 1\n",
            "srnn1: 224\n",
            "dropout_coef: 0.6500000000000001\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 64\n",
            "srnn2: 128\n",
            "dense_0: 224\n",
            "Score: 0.9961298108100891\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_gru: 1\n",
            "srnn1: 288\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "srnn2: 256\n",
            "dense_0: 512\n",
            "srnn3: 64\n",
            "dense_1: 128\n",
            "Score: 0.9960049986839294\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: elu\n",
            "num_gru: 1\n",
            "srnn1: 160\n",
            "dropout_coef: 0.15000000000000002\n",
            "num_denses: 1\n",
            "optimizer: adam\n",
            "batch_size: 800\n",
            "srnn2: 32\n",
            "dense_0: 128\n",
            "Score: 0.9957553148269653\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_gru: 0\n",
            "srnn1: 288\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 64\n",
            "srnn2: 288\n",
            "dense_0: 128\n",
            "srnn3: 224\n",
            "dense_1: 128\n",
            "Score: 0.9947565793991089\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_gru: 0\n",
            "srnn1: 288\n",
            "dropout_coef: 0.35000000000000003\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 672\n",
            "srnn2: 32\n",
            "dense_0: 512\n",
            "srnn3: 256\n",
            "Score: 0.9946317076683044\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_gru: 1\n",
            "srnn1: 288\n",
            "dropout_coef: 0.8500000000000002\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "srnn2: 288\n",
            "dense_0: 128\n",
            "srnn3: 256\n",
            "dense_1: 128\n",
            "Score: 0.9940074682235718\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_gru: 1\n",
            "srnn1: 288\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 608\n",
            "srnn2: 224\n",
            "dense_0: 128\n",
            "srnn3: 128\n",
            "dense_1: 672\n",
            "Score: 0.9928839206695557\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_gru: 1\n",
            "srnn1: 288\n",
            "dropout_coef: 0.8500000000000002\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 64\n",
            "srnn2: 288\n",
            "dense_0: 800\n",
            "Score: 0.9925093650817871\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_gru: 0\n",
            "srnn1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "srnn2: 256\n",
            "dense_0: 480\n",
            "srnn3: 32\n",
            "dense_1: 128\n",
            "Score: 0.9888888597488403\n"
          ]
        }
      ],
      "source": [
        "tuner3.search(x_train,\n",
        "             y_train,\n",
        "             validation_data=(x_val, y_val),\n",
        "             batch_size=hp3.Int('batch_size', min_value=64, max_value=1024, step=32),\n",
        "             epochs=8,\n",
        "             callbacks=[ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.2, min_lr=0.001)]\n",
        "             )\n",
        "\n",
        "tuner3.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djUMwZTKvXbl"
      },
      "source": [
        "Обучаем лучшую модель, тестируем и сохраняем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYHTmi8VZdqa",
        "outputId": "311a95e0-0bb9-4e34-8f67-2c078db1f4cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "44/44 [==============================] - 6s 82ms/step - loss: 1.4429 - accuracy: 0.5839 - val_loss: 0.3372 - val_accuracy: 0.9226 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.3835 - accuracy: 0.8720 - val_loss: 0.1482 - val_accuracy: 0.9702 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "44/44 [==============================] - 3s 65ms/step - loss: 0.2067 - accuracy: 0.9314 - val_loss: 0.1158 - val_accuracy: 0.9655 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "44/44 [==============================] - 3s 73ms/step - loss: 0.1515 - accuracy: 0.9516 - val_loss: 0.0803 - val_accuracy: 0.9747 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "44/44 [==============================] - 3s 69ms/step - loss: 0.1017 - accuracy: 0.9693 - val_loss: 0.1133 - val_accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0860 - accuracy: 0.9749 - val_loss: 0.0408 - val_accuracy: 0.9898 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "44/44 [==============================] - 3s 70ms/step - loss: 0.0521 - accuracy: 0.9860 - val_loss: 0.0530 - val_accuracy: 0.9836 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "44/44 [==============================] - 3s 65ms/step - loss: 0.0644 - accuracy: 0.9798 - val_loss: 0.0233 - val_accuracy: 0.9955 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "44/44 [==============================] - 3s 75ms/step - loss: 0.0345 - accuracy: 0.9925 - val_loss: 0.0157 - val_accuracy: 0.9973 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "44/44 [==============================] - 3s 70ms/step - loss: 0.0265 - accuracy: 0.9938 - val_loss: 0.0181 - val_accuracy: 0.9951 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "44/44 [==============================] - 3s 74ms/step - loss: 0.0288 - accuracy: 0.9927 - val_loss: 0.0179 - val_accuracy: 0.9958 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "44/44 [==============================] - 3s 70ms/step - loss: 0.0303 - accuracy: 0.9920 - val_loss: 0.0142 - val_accuracy: 0.9958 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.1700 - accuracy: 0.9635 - val_loss: 1.4436 - val_accuracy: 0.5995 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 1.3629 - accuracy: 0.6502 - val_loss: 0.1270 - val_accuracy: 0.9688 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "44/44 [==============================] - 3s 61ms/step - loss: 0.1217 - accuracy: 0.9641 - val_loss: 0.0429 - val_accuracy: 0.9913 - lr: 0.0010\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0417 - accuracy: 0.9925\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_2 (SimpleRNN)    (None, 288)               83808     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 288)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               36992     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 27)                3483      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,283\n",
            "Trainable params: 124,283\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 0.99248\n"
          ]
        }
      ],
      "source": [
        "epochs, batch_size = 15, 736\n",
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
        "model6 = Sequential()\n",
        "model6.add(SimpleRNN(288, input_shape=(n_timesteps,n_features)))\n",
        "model6.add(Dropout(0.35))\n",
        "model6.add(Dense(128, activation='selu'))\n",
        "model6.add(Dropout(0.35))\n",
        "model6.add(Dense(n_outputs, activation='softmax'))\n",
        "model6.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "loss6 = model6.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[ReduceLROnPlateau(monitor='val_loss', patience=4, factor=0.2, min_lr=0.001)])\n",
        "_, accuracy = model6.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "model6.summary()\n",
        "print('Accuracy: %.5f' % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.save('drive/My Drive/gr_rnn_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PXJW0waAGJU",
        "outputId": "3b367aaf-48e4-45d6-82a8-462427ffcf96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_rnn_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6pxgDBVYMDM",
        "scrolled": true
      },
      "source": [
        "Теперь построим LSTM модель и подберем параметры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKr-Icy_vXb4"
      },
      "outputs": [],
      "source": [
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
        "\n",
        "def build_modelLSTM(hp):\n",
        "    model = Sequential()\n",
        "    activation_choice = hp.Choice('activation', values=['relu', 'elu', 'selu'])\n",
        "\n",
        "    k = hp.Int('num_lstm', 0, 2)\n",
        "    if k == 0:\n",
        "      model.add(LSTM(hp.Int('lstm1', min_value=32, max_value=600,step=32), input_shape=(n_timesteps,n_features)))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "    elif k == 1:\n",
        "      model.add(LSTM(hp.Int('lstm1', min_value=32, max_value=600,step=32), input_shape=(n_timesteps,n_features), return_sequences=True))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "      model.add(LSTM(hp.Int('lstm2', min_value=32, max_value=600,step=32)))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "    elif k == 2:\n",
        "      model.add(LSTM(hp.Int('lstm1', min_value=32, max_value=600,step=32), input_shape=(n_timesteps,n_features), return_sequences=True))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "      model.add(LSTM(hp.Int('lstm2', min_value=32, max_value=600,step=32), return_sequences=True))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "      model.add(LSTM(hp.Int('lstm3', min_value=32, max_value=600,step=32)))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "\n",
        "    for j in range(hp.Int('num_denses', 0, 2)):\n",
        "        model.add(Dense(units=hp.Int('dense_' + str(j), min_value=128, max_value=600,step=32), activation=activation_choice))\n",
        "        model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "        \n",
        "    model.add(Dense(n_outputs, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=hp.Choice('optimizer', values=['adam','rmsprop','SGD']),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYhTi0juv1Mt",
        "outputId": "0742bd62-e9bd-4dd4-f8a1-9cef8df10332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 6\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu', 'selu'], 'ordered': False}\n",
            "num_lstm (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 2, 'step': 1, 'sampling': None}\n",
            "lstm1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 600, 'step': 32, 'sampling': None}\n",
            "dropout_coef (Float)\n",
            "{'default': 0.05, 'conditions': [], 'min_value': 0.05, 'max_value': 0.9, 'step': 0.1, 'sampling': None}\n",
            "num_denses (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 2, 'step': 1, 'sampling': None}\n",
            "optimizer (Choice)\n",
            "{'default': 'adam', 'conditions': [], 'values': ['adam', 'rmsprop', 'SGD'], 'ordered': False}\n"
          ]
        }
      ],
      "source": [
        "hp5 = HyperParameters()\n",
        "\n",
        "tuner5 = BayesianOptimization(\n",
        "    build_modelLSTM,\n",
        "    hyperparameters=hp5,\n",
        "    objective='val_loss',\n",
        "    max_trials=12,              \n",
        "    directory='lstmgr'\n",
        "    )\n",
        "tuner5.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOSbmtrzv5-Y",
        "outputId": "397aac0c-bb85-4916-a4f1-1aad58c79302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 12 Complete [00h 01m 08s]\n",
            "val_loss: 0.12587788701057434\n",
            "\n",
            "Best val_loss So Far: 0.09142050892114639\n",
            "Total elapsed time: 00h 14m 31s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Results summary\n",
            "Results in lstmgr/untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_loss', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_lstm: 2\n",
            "lstm1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "lstm2: 32\n",
            "dense_0: 128\n",
            "lstm3: 576\n",
            "dense_1: 576\n",
            "Score: 0.09142050892114639\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: elu\n",
            "num_lstm: 2\n",
            "lstm1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 2\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "lstm2: 32\n",
            "dense_0: 128\n",
            "lstm3: 576\n",
            "dense_1: 128\n",
            "Score: 0.0962509959936142\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_lstm: 0\n",
            "lstm1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 2\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "lstm2: 32\n",
            "dense_0: 128\n",
            "lstm3: 32\n",
            "dense_1: 128\n",
            "Score: 0.11174893379211426\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_lstm: 2\n",
            "lstm1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 2\n",
            "optimizer: adam\n",
            "batch_size: 64\n",
            "lstm2: 32\n",
            "dense_0: 128\n",
            "lstm3: 576\n",
            "dense_1: 576\n",
            "Score: 0.12587788701057434\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_lstm: 0\n",
            "lstm1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 2\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "lstm2: 32\n",
            "dense_0: 128\n",
            "lstm3: 576\n",
            "dense_1: 576\n",
            "Score: 0.14450694620609283\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_lstm: 2\n",
            "lstm1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 2\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "lstm2: 32\n",
            "dense_0: 128\n",
            "lstm3: 32\n",
            "dense_1: 416\n",
            "Score: 0.17087295651435852\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_lstm: 2\n",
            "lstm1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "lstm2: 32\n",
            "dense_0: 128\n",
            "lstm3: 32\n",
            "Score: 0.20299313962459564\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_lstm: 1\n",
            "lstm1: 192\n",
            "dropout_coef: 0.25000000000000006\n",
            "num_denses: 1\n",
            "optimizer: rmsprop\n",
            "batch_size: 896\n",
            "lstm2: 32\n",
            "dense_0: 128\n",
            "Score: 0.21562105417251587\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_lstm: 0\n",
            "lstm1: 32\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "lstm2: 32\n",
            "dense_0: 128\n",
            "lstm3: 32\n",
            "dense_1: 576\n",
            "Score: 0.39823657274246216\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_lstm: 2\n",
            "lstm1: 32\n",
            "dropout_coef: 0.8500000000000002\n",
            "num_denses: 2\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "lstm2: 32\n",
            "dense_0: 128\n",
            "lstm3: 160\n",
            "dense_1: 576\n",
            "Score: 1.0845537185668945\n"
          ]
        }
      ],
      "source": [
        "tuner5.search(x_train,\n",
        "             y_train,\n",
        "             validation_data=(x_val, y_val),\n",
        "             batch_size=hp5.Int('batch_size', min_value=64, max_value=1024, step=32),\n",
        "             epochs=4,\n",
        "             callbacks=[ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.2, min_lr=0.001)]\n",
        "             )\n",
        "\n",
        "tuner5.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpgoTelil3Cy"
      },
      "source": [
        "Обучаем лучшую модель, проверяем на тестовом множестве и сохраняем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYDG33skFeF4",
        "outputId": "7a9fd7f8-9eac-4d64-d167-e86957c548c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 12s 180ms/step - loss: 3.0687 - accuracy: 0.0783 - val_loss: 2.6260 - val_accuracy: 0.1303 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 2.2943 - accuracy: 0.2362 - val_loss: 2.0127 - val_accuracy: 0.3101 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 1.6763 - accuracy: 0.4170 - val_loss: 1.3082 - val_accuracy: 0.5581 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 4s 139ms/step - loss: 1.2833 - accuracy: 0.5412 - val_loss: 0.9090 - val_accuracy: 0.6858 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.9594 - accuracy: 0.6617 - val_loss: 0.6590 - val_accuracy: 0.7615 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.6697 - accuracy: 0.7525 - val_loss: 0.5549 - val_accuracy: 0.7933 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.5111 - accuracy: 0.8078 - val_loss: 0.3891 - val_accuracy: 0.8640 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.4334 - accuracy: 0.8401 - val_loss: 0.3644 - val_accuracy: 0.8622 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.3916 - accuracy: 0.8503 - val_loss: 0.3092 - val_accuracy: 0.8798 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.3356 - accuracy: 0.8722 - val_loss: 0.2347 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.2981 - accuracy: 0.8876 - val_loss: 0.2646 - val_accuracy: 0.8931 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.3266 - accuracy: 0.8792 - val_loss: 0.2352 - val_accuracy: 0.9142 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.2803 - accuracy: 0.8955 - val_loss: 0.1960 - val_accuracy: 0.9288 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.2574 - accuracy: 0.9024 - val_loss: 0.1676 - val_accuracy: 0.9447 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.2117 - accuracy: 0.9212 - val_loss: 0.2035 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.2083 - accuracy: 0.9212 - val_loss: 0.1796 - val_accuracy: 0.9273 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 4s 136ms/step - loss: 0.1782 - accuracy: 0.9331 - val_loss: 0.1321 - val_accuracy: 0.9524 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.1718 - accuracy: 0.9361 - val_loss: 0.1107 - val_accuracy: 0.9579 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.1527 - accuracy: 0.9423 - val_loss: 0.0925 - val_accuracy: 0.9669 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.1381 - accuracy: 0.9473 - val_loss: 0.1081 - val_accuracy: 0.9598 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 5s 142ms/step - loss: 0.1701 - accuracy: 0.9347 - val_loss: 0.1667 - val_accuracy: 0.9447 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 4s 136ms/step - loss: 0.1418 - accuracy: 0.9472 - val_loss: 0.0985 - val_accuracy: 0.9668 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.1270 - accuracy: 0.9532 - val_loss: 0.0779 - val_accuracy: 0.9733 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.1189 - accuracy: 0.9558 - val_loss: 0.0777 - val_accuracy: 0.9727 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.1070 - accuracy: 0.9593 - val_loss: 0.0733 - val_accuracy: 0.9722 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.1054 - accuracy: 0.9603 - val_loss: 0.1477 - val_accuracy: 0.9382 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.1255 - accuracy: 0.9518 - val_loss: 0.0564 - val_accuracy: 0.9839 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0851 - accuracy: 0.9674 - val_loss: 0.0484 - val_accuracy: 0.9840 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0797 - accuracy: 0.9704 - val_loss: 0.0580 - val_accuracy: 0.9793 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.1554 - accuracy: 0.9468 - val_loss: 0.0893 - val_accuracy: 0.9680 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 5s 144ms/step - loss: 0.1051 - accuracy: 0.9611 - val_loss: 0.0540 - val_accuracy: 0.9828 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 4s 136ms/step - loss: 0.0779 - accuracy: 0.9708 - val_loss: 0.0453 - val_accuracy: 0.9850 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0803 - accuracy: 0.9695 - val_loss: 0.0430 - val_accuracy: 0.9859 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0741 - accuracy: 0.9725 - val_loss: 0.0719 - val_accuracy: 0.9727 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.1003 - accuracy: 0.9621 - val_loss: 0.0707 - val_accuracy: 0.9737 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0744 - accuracy: 0.9718 - val_loss: 0.0508 - val_accuracy: 0.9806 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0715 - accuracy: 0.9732 - val_loss: 0.0418 - val_accuracy: 0.9871 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0671 - accuracy: 0.9748 - val_loss: 0.0473 - val_accuracy: 0.9840 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0557 - accuracy: 0.9792 - val_loss: 0.0403 - val_accuracy: 0.9859 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0531 - accuracy: 0.9798 - val_loss: 0.0349 - val_accuracy: 0.9884 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0535 - accuracy: 0.9808 - val_loss: 0.0333 - val_accuracy: 0.9903 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0568 - accuracy: 0.9789 - val_loss: 0.0443 - val_accuracy: 0.9851 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0577 - accuracy: 0.9777 - val_loss: 0.0359 - val_accuracy: 0.9895 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0560 - accuracy: 0.9785 - val_loss: 0.0388 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0458 - accuracy: 0.9825 - val_loss: 0.0303 - val_accuracy: 0.9918 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0488 - accuracy: 0.9813 - val_loss: 0.0335 - val_accuracy: 0.9904 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0625 - accuracy: 0.9766 - val_loss: 0.0391 - val_accuracy: 0.9874 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0461 - accuracy: 0.9829 - val_loss: 0.0263 - val_accuracy: 0.9916 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0488 - accuracy: 0.9811 - val_loss: 0.0322 - val_accuracy: 0.9885 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0454 - accuracy: 0.9820 - val_loss: 0.0273 - val_accuracy: 0.9906 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0419 - accuracy: 0.9838 - val_loss: 0.0565 - val_accuracy: 0.9735 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0435 - accuracy: 0.9842 - val_loss: 0.0232 - val_accuracy: 0.9931 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0341 - accuracy: 0.9880 - val_loss: 0.0341 - val_accuracy: 0.9888 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0403 - accuracy: 0.9841 - val_loss: 0.0421 - val_accuracy: 0.9833 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0381 - accuracy: 0.9864 - val_loss: 0.0260 - val_accuracy: 0.9905 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0410 - accuracy: 0.9847 - val_loss: 0.0342 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0437 - accuracy: 0.9838 - val_loss: 0.0466 - val_accuracy: 0.9800 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0491 - accuracy: 0.9808 - val_loss: 0.0557 - val_accuracy: 0.9764 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0416 - accuracy: 0.9844 - val_loss: 0.0263 - val_accuracy: 0.9923 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0363 - accuracy: 0.9854 - val_loss: 0.0302 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0377 - accuracy: 0.9855 - val_loss: 0.0495 - val_accuracy: 0.9834 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0474 - accuracy: 0.9831 - val_loss: 0.0277 - val_accuracy: 0.9906 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 0.0200 - val_accuracy: 0.9941 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0375 - accuracy: 0.9856 - val_loss: 0.0228 - val_accuracy: 0.9914 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 4s 139ms/step - loss: 0.0275 - accuracy: 0.9897 - val_loss: 0.0201 - val_accuracy: 0.9934 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0242 - accuracy: 0.9909 - val_loss: 0.0178 - val_accuracy: 0.9945 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0420 - accuracy: 0.9846 - val_loss: 0.0465 - val_accuracy: 0.9843 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0346 - accuracy: 0.9868 - val_loss: 0.0206 - val_accuracy: 0.9939 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0267 - accuracy: 0.9902 - val_loss: 0.0320 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0292 - accuracy: 0.9894 - val_loss: 0.0251 - val_accuracy: 0.9910 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0298 - accuracy: 0.9894 - val_loss: 0.0268 - val_accuracy: 0.9899 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0300 - accuracy: 0.9889 - val_loss: 0.0250 - val_accuracy: 0.9914 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0433 - accuracy: 0.9835 - val_loss: 0.0253 - val_accuracy: 0.9901 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0816 - accuracy: 0.9737 - val_loss: 0.0488 - val_accuracy: 0.9850 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0445 - accuracy: 0.9842 - val_loss: 0.0275 - val_accuracy: 0.9909 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0335 - accuracy: 0.9879 - val_loss: 0.0210 - val_accuracy: 0.9936 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.0209 - val_accuracy: 0.9929 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0231 - accuracy: 0.9914 - val_loss: 0.0189 - val_accuracy: 0.9934 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0263 - accuracy: 0.9904 - val_loss: 0.0234 - val_accuracy: 0.9921 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0255 - accuracy: 0.9907 - val_loss: 0.0228 - val_accuracy: 0.9920 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0205 - accuracy: 0.9924 - val_loss: 0.0155 - val_accuracy: 0.9950 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0209 - accuracy: 0.9918 - val_loss: 0.0230 - val_accuracy: 0.9916 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0209 - accuracy: 0.9922 - val_loss: 0.1079 - val_accuracy: 0.9635 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0705 - accuracy: 0.9767 - val_loss: 0.0295 - val_accuracy: 0.9889 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.0196 - val_accuracy: 0.9939 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0228 - accuracy: 0.9912 - val_loss: 0.0186 - val_accuracy: 0.9936 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.0161 - val_accuracy: 0.9945 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0214 - accuracy: 0.9917 - val_loss: 0.0252 - val_accuracy: 0.9923 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.0176 - val_accuracy: 0.9948 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0198 - accuracy: 0.9925 - val_loss: 0.0173 - val_accuracy: 0.9953 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.1474 - accuracy: 0.9564 - val_loss: 0.0550 - val_accuracy: 0.9823 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0456 - accuracy: 0.9846 - val_loss: 0.0256 - val_accuracy: 0.9926 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0332 - accuracy: 0.9883 - val_loss: 0.0216 - val_accuracy: 0.9933 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0292 - accuracy: 0.9894 - val_loss: 0.0172 - val_accuracy: 0.9955 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0214 - accuracy: 0.9923 - val_loss: 0.0151 - val_accuracy: 0.9950 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 0.0173 - val_accuracy: 0.9939 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0263 - accuracy: 0.9901 - val_loss: 0.0214 - val_accuracy: 0.9923 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.0178 - accuracy: 0.9934 - val_loss: 0.0135 - val_accuracy: 0.9961 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0215 - accuracy: 0.9918 - val_loss: 0.0167 - val_accuracy: 0.9944 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 4s 137ms/step - loss: 0.0202 - accuracy: 0.9927 - val_loss: 0.0121 - val_accuracy: 0.9965 - lr: 0.0010\n",
            "17/17 [==============================] - 1s 42ms/step - loss: 0.0135 - accuracy: 0.9957\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_12 (LSTM)              (None, 21, 32)            4480      \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 21, 32)            0         \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 21, 32)            8320      \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 21, 32)            0         \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 576)               1403136   \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 576)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 128)               73856     \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 27)                3483      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,493,275\n",
            "Trainable params: 1,493,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 0.99575\n"
          ]
        }
      ],
      "source": [
        "epochs, batch_size = 100, 1024\n",
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
        "model9 = Sequential()\n",
        "model9.add(LSTM(32, input_shape=(n_timesteps,n_features), return_sequences=True))\n",
        "model9.add(Dropout(0.05))\n",
        "model9.add(LSTM(32, return_sequences=True))\n",
        "model9.add(Dropout(0.05))\n",
        "model9.add(LSTM(576))\n",
        "model9.add(Dropout(0.05))\n",
        "model9.add(Dense(128, activation='relu'))\n",
        "model9.add(Dropout(0.05))\n",
        "model9.add(Dense(n_outputs, activation='softmax'))\n",
        "model9.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "loss9 = model9.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[ReduceLROnPlateau(monitor='val_accuracy', patience=4, factor=0.2, min_lr=0.001)])\n",
        "_, accuracy = model9.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "model9.summary()\n",
        "print('Accuracy: %.5f' % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model9.save('drive/My Drive/gr_lstm1_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg758NaIyTbh",
        "outputId": "210ddb13-4d28-4bc5-bb1b-7cab6b74bd63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_lstm1_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_lstm1_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fcc208f95d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fcbf7bc2850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fcbf7a89950> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcpMSRh5mnE3"
      },
      "source": [
        "Ещё одна модель LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdjDq4wBHnWL",
        "outputId": "af868054-fe37-426c-ea6c-e552ea75744a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "501/501 [==============================] - 12s 18ms/step - loss: 1.5989 - accuracy: 0.4791 - val_loss: 0.8542 - val_accuracy: 0.7052 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6792 - accuracy: 0.7622 - val_loss: 0.3399 - val_accuracy: 0.8722 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.4065 - accuracy: 0.8571 - val_loss: 0.3565 - val_accuracy: 0.8866 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.2731 - accuracy: 0.9033 - val_loss: 0.2225 - val_accuracy: 0.9065 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.1961 - accuracy: 0.9310 - val_loss: 0.1173 - val_accuracy: 0.9558 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.1608 - accuracy: 0.9411 - val_loss: 0.2197 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.1332 - accuracy: 0.9526 - val_loss: 0.0558 - val_accuracy: 0.9820 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.1236 - accuracy: 0.9548 - val_loss: 0.1462 - val_accuracy: 0.9562 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.1106 - accuracy: 0.9601 - val_loss: 0.1012 - val_accuracy: 0.9663 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0957 - accuracy: 0.9667 - val_loss: 0.0598 - val_accuracy: 0.9828 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0889 - accuracy: 0.9693 - val_loss: 0.5556 - val_accuracy: 0.8436 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0791 - accuracy: 0.9732 - val_loss: 0.1170 - val_accuracy: 0.9588 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0721 - accuracy: 0.9770 - val_loss: 0.1971 - val_accuracy: 0.9360 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0629 - accuracy: 0.9787 - val_loss: 0.0246 - val_accuracy: 0.9928 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0586 - accuracy: 0.9809 - val_loss: 0.0407 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0552 - accuracy: 0.9830 - val_loss: 0.0303 - val_accuracy: 0.9904 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 0.0359 - val_accuracy: 0.9871 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0458 - accuracy: 0.9857 - val_loss: 0.0597 - val_accuracy: 0.9805 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0438 - accuracy: 0.9870 - val_loss: 0.0223 - val_accuracy: 0.9943 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 0.0437 - val_accuracy: 0.9868 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0360 - accuracy: 0.9889 - val_loss: 0.0360 - val_accuracy: 0.9885 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.0312 - accuracy: 0.9908 - val_loss: 0.0183 - val_accuracy: 0.9944 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.0300 - accuracy: 0.9907 - val_loss: 0.1158 - val_accuracy: 0.9790 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.0255 - accuracy: 0.9929 - val_loss: 0.0086 - val_accuracy: 0.9981 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0264 - accuracy: 0.9925 - val_loss: 0.0127 - val_accuracy: 0.9978 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 0.0111 - val_accuracy: 0.9975 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.0256 - accuracy: 0.9936 - val_loss: 0.0176 - val_accuracy: 0.9968 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0242 - accuracy: 0.9929 - val_loss: 0.0219 - val_accuracy: 0.9933 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0217 - accuracy: 0.9939 - val_loss: 0.0090 - val_accuracy: 0.9985 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.0105 - val_accuracy: 0.9976 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.0086 - val_accuracy: 0.9980 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.0080 - val_accuracy: 0.9984 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0361 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.0109 - val_accuracy: 0.9976 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0159 - val_accuracy: 0.9963 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.0070 - val_accuracy: 0.9986 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 0.0175 - val_accuracy: 0.9954 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0081 - val_accuracy: 0.9985 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0094 - val_accuracy: 0.9975 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.0115 - val_accuracy: 0.9975 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.0111 - val_accuracy: 0.9974 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.0191 - val_accuracy: 0.9955 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.0070 - val_accuracy: 0.9989 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0079 - val_accuracy: 0.9986 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.0083 - val_accuracy: 0.9984 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0142 - accuracy: 0.9968 - val_loss: 0.0081 - val_accuracy: 0.9985 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.0149 - val_accuracy: 0.9965 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0896 - val_accuracy: 0.9816 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 0.0166 - val_accuracy: 0.9953 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.0083 - val_accuracy: 0.9985 - lr: 0.0010\n",
            "269/269 [==============================] - 2s 6ms/step - loss: 0.0060 - accuracy: 0.9985\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_15 (LSTM)              (None, 224)               203392    \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 224)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 27)                6075      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209,467\n",
            "Trainable params: 209,467\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 0.99854\n"
          ]
        }
      ],
      "source": [
        "epochs, batch_size = 50, 64\n",
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
        "model4 = Sequential()\n",
        "model4.add(LSTM(224, input_shape=(n_timesteps,n_features)))\n",
        "model4.add(Dropout(0.05))\n",
        "model4.add(Dense(n_outputs, activation='softmax'))\n",
        "model4.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "loss4 = model4.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[ReduceLROnPlateau(monitor='val_accuracy', patience=5, factor=0.2, min_lr=0.001)])\n",
        "_, accuracy = model4.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "model4.summary()\n",
        "print('Accuracy: %.5f' % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.save('drive/My Drive/gr_lstm_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPKTYr4s1A_i",
        "outputId": "5fccbc48-3110-4095-8ee1-1fa271c79fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_lstm_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_lstm_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fcbf7d79dd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us0-HwmqvXb1"
      },
      "source": [
        "Строим GRU модель и подбираем параметры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJLqrrpCukgp"
      },
      "outputs": [],
      "source": [
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
        "\n",
        "def build_modelGRU(hp):\n",
        "    model = Sequential()\n",
        "    activation_choice = hp.Choice('activation', values=['relu', 'elu', 'selu'])\n",
        "\n",
        "    k = hp.Int('num_gru', 0, 2)\n",
        "    if k == 0:\n",
        "      model.add(GRU(hp.Int('gru1', min_value=32, max_value=400,step=32), input_shape=(n_timesteps,n_features)))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "    elif k == 1:\n",
        "      model.add(GRU(hp.Int('gru1', min_value=32, max_value=400,step=32), input_shape=(n_timesteps,n_features), return_sequences=True))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "      model.add(GRU(hp.Int('gru2', min_value=32, max_value=400,step=32)))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "    elif k == 2:\n",
        "      model.add(GRU(hp.Int('gru1', min_value=32, max_value=400,step=32), input_shape=(n_timesteps,n_features), return_sequences=True))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "      model.add(GRU(hp.Int('gru2', min_value=32, max_value=400,step=32), return_sequences=True))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "      model.add(GRU(hp.Int('gru3', min_value=32, max_value=400,step=32)))\n",
        "      model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "\n",
        "    for j in range(hp.Int('num_denses', 0, 2)):\n",
        "        model.add(Dense(units=hp.Int('dense_' + str(j), min_value=128, max_value=600,step=32), activation=activation_choice))\n",
        "        model.add(Dropout(hp.Float('dropout_coef', min_value=0.05, max_value=0.9, step=0.1)))\n",
        "        \n",
        "    model.add(Dense(n_outputs, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=hp.Choice('optimizer', values=['adam','rmsprop','SGD']),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChA4lcUZYMDO",
        "outputId": "d237ecba-e0e5-4d5d-c435-d496987732a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 6\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu', 'selu'], 'ordered': False}\n",
            "num_gru (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 2, 'step': 1, 'sampling': None}\n",
            "gru1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 400, 'step': 32, 'sampling': None}\n",
            "dropout_coef (Float)\n",
            "{'default': 0.05, 'conditions': [], 'min_value': 0.05, 'max_value': 0.9, 'step': 0.1, 'sampling': None}\n",
            "num_denses (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 2, 'step': 1, 'sampling': None}\n",
            "optimizer (Choice)\n",
            "{'default': 'adam', 'conditions': [], 'values': ['adam', 'rmsprop', 'SGD'], 'ordered': False}\n"
          ]
        }
      ],
      "source": [
        "hp2 = HyperParameters()\n",
        "\n",
        "tuner2 = BayesianOptimization(\n",
        "    build_modelGRU,\n",
        "    hyperparameters=hp2,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=12,              \n",
        "    directory='grugr'\n",
        "    )\n",
        "tuner2.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGkuzZMkYMDP",
        "outputId": "c499ec98-7e3d-4e11-eee8-b591c6cac78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 12 Complete [00h 00m 28s]\n",
            "val_accuracy: 0.9535580277442932\n",
            "\n",
            "Best val_accuracy So Far: 0.9951310753822327\n",
            "Total elapsed time: 00h 15m 12s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in grugr/untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_gru: 1\n",
            "gru1: 384\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 64\n",
            "gru2: 384\n",
            "dense_0: 576\n",
            "dense_1: 128\n",
            "Score: 0.9951310753822327\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: elu\n",
            "num_gru: 1\n",
            "gru1: 320\n",
            "dropout_coef: 0.45000000000000007\n",
            "num_denses: 1\n",
            "optimizer: adam\n",
            "batch_size: 544\n",
            "gru2: 160\n",
            "dense_0: 288\n",
            "dense_1: 320\n",
            "Score: 0.9942571520805359\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_gru: 1\n",
            "gru1: 384\n",
            "dropout_coef: 0.8500000000000002\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 352\n",
            "gru2: 320\n",
            "dense_0: 480\n",
            "dense_1: 576\n",
            "Score: 0.9932584166526794\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_gru: 2\n",
            "gru1: 384\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 224\n",
            "gru2: 384\n",
            "dense_0: 128\n",
            "dense_1: 576\n",
            "gru3: 384\n",
            "Score: 0.9915106296539307\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_gru: 2\n",
            "gru1: 384\n",
            "dropout_coef: 0.7500000000000002\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 128\n",
            "gru2: 32\n",
            "dense_0: 576\n",
            "dense_1: 224\n",
            "gru3: 384\n",
            "Score: 0.989513099193573\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_gru: 2\n",
            "gru1: 384\n",
            "dropout_coef: 0.05\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "gru2: 96\n",
            "dense_0: 576\n",
            "dense_1: 576\n",
            "gru3: 32\n",
            "Score: 0.9886391758918762\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_gru: 0\n",
            "gru1: 384\n",
            "dropout_coef: 0.5500000000000002\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 1024\n",
            "gru2: 384\n",
            "dense_0: 448\n",
            "dense_1: 224\n",
            "gru3: 384\n",
            "Score: 0.9823970198631287\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: selu\n",
            "num_gru: 0\n",
            "gru1: 384\n",
            "dropout_coef: 0.15000000000000002\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 64\n",
            "gru2: 160\n",
            "dense_0: 576\n",
            "dense_1: 576\n",
            "gru3: 320\n",
            "Score: 0.9735330939292908\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_gru: 0\n",
            "gru1: 384\n",
            "dropout_coef: 0.35000000000000003\n",
            "num_denses: 0\n",
            "optimizer: adam\n",
            "batch_size: 64\n",
            "gru2: 32\n",
            "dense_0: 128\n",
            "dense_1: 576\n",
            "gru3: 32\n",
            "Score: 0.9535580277442932\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "num_gru: 2\n",
            "gru1: 384\n",
            "dropout_coef: 0.7500000000000002\n",
            "num_denses: 2\n",
            "optimizer: adam\n",
            "batch_size: 800\n",
            "gru2: 384\n",
            "dense_0: 576\n",
            "dense_1: 576\n",
            "gru3: 384\n",
            "Score: 0.9415730237960815\n"
          ]
        }
      ],
      "source": [
        "tuner2.search(x_train,\n",
        "             y_train,\n",
        "              validation_data=(x_val, y_val),\n",
        "             batch_size=hp2.Int('batch_size', min_value=64, max_value=1024, step=32),\n",
        "             epochs=4,\n",
        "             callbacks=[ReduceLROnPlateau(monitor='val_accuracy', patience=3, factor=0.2, min_lr=0.001)]\n",
        "             )\n",
        "\n",
        "tuner2.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcHlNqIRvXb2"
      },
      "source": [
        "Запускаем полноценное обучение для лучшей модели и проверяем на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6jyc4ZQujM8",
        "outputId": "e9321a86-a811-443e-b75f-0cc1c1b549f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "501/501 [==============================] - 23s 25ms/step - loss: 0.6833 - accuracy: 0.7591 - val_loss: 0.2410 - val_accuracy: 0.9235 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.1338 - accuracy: 0.9537 - val_loss: 0.0522 - val_accuracy: 0.9840 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0627 - accuracy: 0.9795 - val_loss: 0.0191 - val_accuracy: 0.9941 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0375 - accuracy: 0.9888 - val_loss: 0.0193 - val_accuracy: 0.9939 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0328 - accuracy: 0.9898 - val_loss: 0.0268 - val_accuracy: 0.9936 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 0.0114 - val_accuracy: 0.9974 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.0117 - val_accuracy: 0.9966 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.0630 - val_accuracy: 0.9891 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.0082 - val_accuracy: 0.9971 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "501/501 [==============================] - 13s 26ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.0403 - val_accuracy: 0.9878 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0048 - val_accuracy: 0.9986 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.0040 - val_accuracy: 0.9989 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0021 - val_accuracy: 0.9993 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.0085 - val_accuracy: 0.9975 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0068 - val_accuracy: 0.9985 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0047 - val_accuracy: 0.9985 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0090 - val_accuracy: 0.9965 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0021 - val_accuracy: 0.9994 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0309 - val_accuracy: 0.9951 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.0020 - val_accuracy: 0.9990 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0052 - val_accuracy: 0.9989 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0083 - val_accuracy: 0.9969 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0027 - val_accuracy: 0.9989 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0078 - val_accuracy: 0.9983 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0035 - val_accuracy: 0.9988 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0038 - val_accuracy: 0.9993 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0193 - val_accuracy: 0.9948 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0081 - val_accuracy: 0.9974 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0066 - val_accuracy: 0.9978 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 0.9996 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0199 - val_accuracy: 0.9944 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0103 - val_accuracy: 0.9983 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0030 - val_accuracy: 0.9994 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0096 - val_accuracy: 0.9980 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0028 - val_accuracy: 0.9991 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0034 - val_accuracy: 0.9991 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.0059 - val_accuracy: 0.9985 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0038 - val_accuracy: 0.9993 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0048 - val_accuracy: 0.9989 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0061 - val_accuracy: 0.9984 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0103 - val_accuracy: 0.9971 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 6.6040e-04 - accuracy: 0.9999 - val_loss: 0.0035 - val_accuracy: 0.9995 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 9.6526e-04 - accuracy: 0.9998 - val_loss: 0.0033 - val_accuracy: 0.9998 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0048 - val_accuracy: 0.9988 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0057 - val_accuracy: 0.9994 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0080 - val_accuracy: 0.9994 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0192 - val_accuracy: 0.9961 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0076 - val_accuracy: 0.9994 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0071 - val_accuracy: 0.9995 - lr: 0.0010\n",
            "269/269 [==============================] - 3s 11ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_8 (GRU)                 (None, 21, 384)           446976    \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 21, 384)           0         \n",
            "                                                                 \n",
            " gru_9 (GRU)                 (None, 384)               887040    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 384)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 576)               221760    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 576)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 27)                15579     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,571,355\n",
            "Trainable params: 1,571,355\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 0.99953\n"
          ]
        }
      ],
      "source": [
        "epochs, batch_size = 50, 64\n",
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
        "model5 = Sequential()\n",
        "model5.add(GRU(384, input_shape=(n_timesteps,n_features), return_sequences=True))\n",
        "model5.add(Dropout(0.05))\n",
        "model5.add(GRU(384))\n",
        "model5.add(Dropout(0.05))\n",
        "model5.add(Dense(576, activation='relu'))\n",
        "model5.add(Dropout(0.05))\n",
        "model5.add(Dense(n_outputs, activation='softmax'))\n",
        "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "loss5 = model5.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[ReduceLROnPlateau(monitor='val_accuracy', patience=4, factor=0.2, min_lr=0.001)])\n",
        "_, accuracy = model5.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "model5.summary()\n",
        "print('Accuracy: %.5f' % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.save('drive/My Drive/gr_gru_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXnHCUl7CCCx",
        "outputId": "66ef835d-a339-4a9d-ff9f-fd45d1883e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_8_layer_call_fn, gru_cell_8_layer_call_and_return_conditional_losses, gru_cell_9_layer_call_fn, gru_cell_9_layer_call_and_return_conditional_losses, gru_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_gru_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_gru_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f032dabb9d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f03a00b3a90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMQL4bIKvXb3"
      },
      "source": [
        "Построим для GRU-модели двунаправленую модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iowA9ZKgtc5-",
        "outputId": "ae5873c7-bd43-42a2-d656-ddb3610cab2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "501/501 [==============================] - 35s 53ms/step - loss: 0.3695 - accuracy: 0.8735 - val_loss: 0.0371 - val_accuracy: 0.9915 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.0318 - val_accuracy: 0.9906 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 0.0225 - val_accuracy: 0.9920 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0232 - accuracy: 0.9935 - val_loss: 0.0490 - val_accuracy: 0.9865 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0361 - val_accuracy: 0.9881 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.0099 - val_accuracy: 0.9964 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0312 - accuracy: 0.9913 - val_loss: 0.0079 - val_accuracy: 0.9979 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0035 - val_accuracy: 0.9993 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "501/501 [==============================] - 25s 49ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 0.0101 - val_accuracy: 0.9975 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.0370 - val_accuracy: 0.9905 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0209 - val_accuracy: 0.9950 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "501/501 [==============================] - 25s 49ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0056 - val_accuracy: 0.9984 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0152 - val_accuracy: 0.9965 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0021 - val_accuracy: 0.9995 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "501/501 [==============================] - 25s 50ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0054 - val_accuracy: 0.9985 - lr: 0.0010\n",
            "269/269 [==============================] - 5s 18ms/step - loss: 0.0072 - accuracy: 0.9981\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 21, 768)          893952    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 21, 768)           0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 768)              2658816   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 576)               442944    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 27)                15579     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,011,291\n",
            "Trainable params: 4,011,291\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 0.99814\n"
          ]
        }
      ],
      "source": [
        "epochs, batch_size = 15, 64\n",
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
        "model8 = Sequential()\n",
        "model8.add(Bidirectional(GRU(384, return_sequences=True), input_shape=(n_timesteps,n_features)))\n",
        "model8.add(Dropout(0.05))\n",
        "model8.add(Bidirectional(GRU(384)))\n",
        "model8.add(Dropout(0.05))\n",
        "model8.add(Dense(576, activation='relu'))\n",
        "model8.add(Dropout(0.05))\n",
        "model8.add(Dense(n_outputs, activation='softmax'))\n",
        "model8.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "loss8 = model8.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[ReduceLROnPlateau(monitor='accuracy', patience=4, factor=0.2, min_lr=0.001)])\n",
        "_, accuracy = model8.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "model8.summary()\n",
        "print('Accuracy: %.5f' % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8.save('drive/My Drive/gr_bigru_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWbvHFRnQsSU",
        "outputId": "290727e1-36f5-462c-bc67-36f9b268868f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_7_layer_call_fn, gru_cell_7_layer_call_and_return_conditional_losses, gru_cell_8_layer_call_fn, gru_cell_8_layer_call_and_return_conditional_losses, gru_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_bigru_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/gr_bigru_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f5e14474890> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f5e1447d1d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f5e143087d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f5e14308810> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ksad_3_ (1) (4).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}